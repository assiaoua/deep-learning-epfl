{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(0)\n",
    "from others.otherfile1 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upload our datasets:\n",
    "- train_data = the training data and corresponds to 50000 noisy pairs of images. Each of the 50000 pairs provided correspond to downsampled, pixelated images\n",
    "- val_data = validation file to track your progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_imgs_1 , noisy_imgs_2 = torch.load('data/train_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_imgs, clean_imgs = torch.load('data/val_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of noisy_imgs_1', noisy_imgs_1.shape)\n",
    "print('Shape of noisy_imgs_2', noisy_imgs_2.shape)\n",
    "print('Shape of noisy_imgs', noisy_imgs.shape)\n",
    "print('Shape of clean_imgs', clean_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show one the images of all of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(noisy_imgs_1[135,1])\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(noisy_imgs_2[135,1])\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(noisy_imgs[135,1])\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(clean_imgs[135,1])\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the validation and train data is different. The train data is composed of 2 same images pixelated differently, while the validation data is composed of one noisy image and its correponding clean image. Notice that their shape is also different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any further analysis, let's split our dataset into 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_1, test_set_1 = split_train_test(noisy_imgs_1)\n",
    "train_set_2, test_set_2 = split_train_test(noisy_imgs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of train_set_1', train_set_1.shape)\n",
    "print('Shape of test_set_1', test_set_1.shape)\n",
    "print('Shape of train_set_2', train_set_2.shape)\n",
    "print('Shape of test_set_2', test_set_2.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
