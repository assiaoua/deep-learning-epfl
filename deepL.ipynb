{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17jzMbDxhCcedBsf9ZPLxynds8h5BEGXi",
      "authorship_tag": "ABX9TyNaWtAN8W5w1o9avFBy6z1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/assiaoua/deep-learning-epfl/blob/main/deepL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y1njwl-XZ_sD"
      },
      "outputs": [],
      "source": [
        "### For mini - project 1\n",
        "from ast import Mod\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "def psnr(denoised , ground_truth):\n",
        "    # Peak Signal to Noise Ratio: denoised and ground_truth have range [0, 1] \n",
        "    mse = torch.mean((denoised - ground_truth) ** 2)\n",
        "    return -10 * torch.log10(mse + 10**-8)\n",
        "\n",
        "class Model(nn.Module) :\n",
        "    def __init__ (self):\n",
        "        ## instantiate model + optimizer + loss function + any other stuff you need\n",
        "        super(Model, self).__init__()\n",
        "        self.autoencoder = nn.Sequential(\n",
        "                                ## encoder\n",
        "                                nn.Conv2d(3, 32, kernel_size = 3, stride = 1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.Conv2d(32, 32, kernel_size = 3, stride = 1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.Conv2d(32, 32, kernel_size = 3, stride = 1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.Conv2d(32, 32, kernel_size = 3, stride = 1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.Conv2d(32, 8, kernel_size = 3, stride = 1),\n",
        "                                ## decoder\n",
        "                                nn.ConvTranspose2d(8, 32, kernel_size=3, stride=1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1),\n",
        "                                nn.LeakyReLU(0.1),\n",
        "                                nn.ConvTranspose2d(32, 3, kernel_size=1, stride=1)        \n",
        "            )\n",
        "        \n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = torch.optim.Adam(self.autoencoder.parameters(), lr=1e-3)\n",
        "        self.mini_batch_size = 100\n",
        "        self.eta = 1e-1\n",
        "        \n",
        "\n",
        "    def load_pretrained_model(self):\n",
        "        ## This loads the parameters saved in bestmodel .pth into the model\n",
        "        \n",
        "        self.load_state_dict(torch.load(\"bestmodel.pth\"))\n",
        "        self.eval()\n",
        "            \n",
        "\n",
        "    def train(self, train_input, train_target, num_epochs):\n",
        "        #: train_input : tensor of size (N, C, H, W) containing a noisy version of the images\n",
        "        #: train_target : tensor of size (N, C, H, W) containing another noisy version of the same images, which only differs from the input by their noise.\n",
        "        for e in range(num_epochs):\n",
        "            acc_loss = 0\n",
        "            for b in range(0, train_input.size(0), self.mini_batch_size):\n",
        "                output = self.autoencoder(train_input.narrow(0, b, self.mini_batch_size))\n",
        "                loss = self.criterion(output, train_target.narrow(0, b, self.mini_batch_size))\n",
        "                acc_loss = acc_loss + loss.item()\n",
        "                \n",
        "                self.autoencoder.zero_grad()\n",
        "                loss.backward()\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for p in self.autoencoder.parameters():\n",
        "                        p -= self.eta * p.grad\n",
        "\n",
        "            print(e, acc_loss)\n",
        "\n",
        "    def predict(self, test_input):\n",
        "        #: test_input : tensor of size (N1 , C, H, W) that has to be denoised by the trained or the loaded network .\n",
        "        return self.autoencoder(test_input)    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "noisy_imgs_1 , noisy_imgs_2 = torch.load('drive/MyDrive/data/train_data.pkl')\n",
        "noisy_imgs_1 = noisy_imgs_1[:10000].to(device)\n",
        "noisy_imgs_2 = noisy_imgs_2[:10000].to(device)\n",
        "noisy_imgs, clean_imgs = torch.load('drive/MyDrive/data/val_data.pkl')\n",
        "noisy_imgs = noisy_imgs.to(device)\n",
        "clean_imgs = clean_imgs.to(device)\n",
        "print('Shape of noisy_imgs_1', noisy_imgs_1.shape)\n",
        "print('Shape of noisy_imgs_2', noisy_imgs_2.shape)\n",
        "print('Shape of noisy_imgs', noisy_imgs.shape)\n",
        "print('Shape of clean_imgs', clean_imgs.shape)\n",
        "\n",
        "noisy_imgs_1 = noisy_imgs_1 / 255\n",
        "noisy_imgs_2 = noisy_imgs_2 / 255\n",
        "noisy_imgs = noisy_imgs / 255\n",
        "clean_imgs = clean_imgs / 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BohTVYGjw-G",
        "outputId": "189800b1-22b3-4aaf-8e34-c112c32fdc4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of noisy_imgs_1 torch.Size([10000, 3, 32, 32])\n",
            "Shape of noisy_imgs_2 torch.Size([10000, 3, 32, 32])\n",
            "Shape of noisy_imgs torch.Size([1000, 3, 32, 32])\n",
            "Shape of clean_imgs torch.Size([1000, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)\n",
        "model.train(noisy_imgs_1, noisy_imgs_2, 100)\n",
        "prediction = model.predict(noisy_imgs)\n",
        "nb_test_errors = psnr(prediction, clean_imgs)\n",
        "print('test error Net', nb_test_errors)\n",
        "\n",
        "model = Model()\n",
        "\n",
        "FILE = \"bestmodel.pth\"\n",
        "torch.save(model.state_dict, FILE)\n",
        "\n",
        "\n",
        "\"\"\" loaded = Model()\n",
        "loaded.load_state_dict(torch.load(FILE))\n",
        "loaded.eval() \"\"\"\n",
        "\n",
        "\n",
        "'''\n",
        "TO DO :\n",
        "- save and load_pretrained_model() for the best model \n",
        "- optimize our model\n",
        "- test the predictions\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty73IbieaC0g",
        "outputId": "97b64073-d0e0-4b1e-b22e-0f6b4810ea31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 8.268323868513107\n",
            "1 7.450102888047695\n",
            "2 7.4304585084319115\n",
            "3 7.421369947493076\n",
            "4 7.416279956698418\n",
            "5 7.412992626428604\n",
            "6 7.4105722308158875\n",
            "7 7.4084432646632195\n",
            "8 7.406057499349117\n",
            "9 7.402600452303886\n",
            "10 7.395965069532394\n",
            "11 7.378970727324486\n",
            "12 7.289138466119766\n",
            "13 6.175636064261198\n",
            "14 5.152186863124371\n",
            "15 4.93410200625658\n",
            "16 4.83924625068903\n",
            "17 4.787207562476397\n",
            "18 4.784322317689657\n",
            "19 4.7162621058523655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PulomNsck9C",
        "outputId": "1fe9aed9-b72b-45ba-ff89-729c93cf1116"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIRxs2A9iq-L",
        "outputId": "d8b3ce35-2c0c-4b56-dc8e-7f3e5b333665"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s5KPwuA8is0n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}